\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{tikz}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage[latin1]{inputenc}  

     
\sloppy

\title{Utilização de Chain-of-Thought Prompting para classificação de questões da OBI}

\author{Davi Queiroz Rodrigues\inst{1}, Rodrigo Seiti Koga Kikuta\inst{1}, \\ Amaury Antonio de Castro Júnior\inst{1}}

\address{Faculdade de Computação (FACOM)\\
  Universidade Federal do Mato Grosso do Sul
  (UFMS)\\
  79070-900 -- Campo Grande -- MS -- Brasil
  \email{{davi\_queiroz@ufms.br}, {rodrigo\_seiti}@ufms.br, amaury.junior@ufms.br}
}

\begin{document} 

\maketitle

\begin{abstract}
  This paper focuses on an analysis of the structure of questions in the OBI (Brazilian Informatics Olympiad) initiation category and explores how Chain-of-Thought prompting can be used for question classification, particularly to assess whether the currently available study materials are compatible with the most recent exams.
\end{abstract}
     
\begin{resumo} 
  Este artigo foca em uma análise da estrutura das questões da OBI na modalidade iniciação e como podemos utilizar Chain-of-thought promping para a classificação das questões, particularmente para entendermos se os materiais de estudo atuais disponíveis são compatíveis com as provas mais recentes.
\end{resumo}


\section{Introdução}

A Olimpíada Brasileira de Informática (OBI)\cite{1} é uma competição organizada nos moldes das outras olimpíadas científicas brasileiras, a OBI é organizada em duas modalidades, iniciação e programação.
Na modalidade iniciação, alunos que ainda não sabem programar competem resolvendo problemas de lógica, conceitos de computação e matemática. A prova é dividida em níveis (júnior, 1 e 2) e fases (2 definidas pelo calendário da OBI, mas podem possuir mais). No site da olimpíada existe uma seção de preparação, onde o único material indicado para a preparação da prova é o livro Jogos de Lógica \cite{2}.
Em seu livro \cite{2}, são descritas classes e tipos de questões, bem como seus métodos de resolução, contudo o conjunto de questões contempladas, são as questões da OBI 2003 a OBI 2009.

    Diante desse fato, esse artigo aborda a utilização da técnica Chain-of-Thought promping para classificação de questões de edições mais recentes da olimpíada e como auxílio para avaliar a adequação das classes e tipos apresentadas no livro Jogos de Lógica\cite{2}.

\section{Fundamento Teórico} \label{sec:fundamento}

Modelos de linguagem de grande escala (LLMs), como o GPT-4, são modelos que usam aprendizado de máquina para processar e analisar linguagem humana\cite{3}. Com a constante melhoria do seu algoritmo e poder de processamento, LLMs tem a capacidade de processar e analisar dados contextuais, permitindo assim aplicações específicas. A precisão das respostas de uma LLM pode ser influenciada pelo uso de técnicas de prompting especializada como, por exemplo, zero-shot prompting, one-shot prompting ou chain-of-thought prompting\cite{4}.

\subsection{Zero-Shot Prompting}

Zero-shot prompting é a técnica na qual é requisitado ao modelo que faça uma tarefa sem treinamento prévio ou exemplos daquela tarefa em específico\cite{5}, utilizando apenas o seu conhecimento pré-existente para inferir como lidar com essa nova tarefa. A técnica é boa para tarefas genéricas mas é imprecisa quando lida com atividades com muita complexidade.

\subsection{One-Shot Prompting}

Essa técnica disponhe ao modelo um exemplo para guiar a resolução da tarefa antes de apresentar a tarefa em si. Mostrando um problema relacionado e a sua solução, o modelo agora tem uma base para resolução da tarefa. Apresenta resultados mais precisos que o do zero-shot, mas ainda assim pode apresentar erros pela falta de entendimento contextual.

\subsection{Chain-of-Thought Prompting}

Chain-of-Thought prompting é a técnica que força a LLM executar a tarefa com um foco maior no contexto. As LLMs funcionam prevendo a próxima palavra em uma sequência baseado no contexto das palavras anteriores, isso acaba por vezes causando a perda da semântica da análise ou conversa. Ao utilizarmos o chain-of-thought, a tarefa é dividida em passos lógicos, de forma que possamos guiar a LLM a uma linha de pensamento que se assemelha a como um humano resolveria determinada tarefa.

    A implementação da técnica geralmente inclui um exemplo da tarefa com um conjunto de decisões tomadas para determinada conclusão e um prompt que deixa explicito a necessidade de demonstrar os passos tomados para a decisão. Por exemplo, em um problema matemático, pedir para que o modelo demonstre cada passo efetuado do cálculo. Isso força o modelo atacar o problema de forma sequencial, bem como um humano faria para um problema extenso ou complexo.

\section{Classificação das Questões} \label{sec:class}
Como abordado no livro Jogos de Lógicas\cite{2}, as questões podem ser classificadas em "Classes", que determinam a utilização das variáveis apresentadas na questão, e cada classe possui um conjunto de "Tipos" que determinam o tipo de restrição que será aplicada as variáveis da questão.

\begin{itemize}
    \item Ordenação: Envolve posicionar elementos em uma sequência específica relativa a algum sistema. Os tipos dessa classe são:
    \begin{itemize}
        \item Linear: Lidam com uma única estrutura linear;
        \item Quadrática: Lidam com uma ou mais estruturas lineares sobrepostas;
        \item Circular:  Lidam com uma estrutura em que as extremidades se encontram;
        \item Lidam com uma estrutura não definida ou que se assemelha a um grafo.
    \end{itemize}
    \item Agrupamento: Divide elementos em grupos com base em características ou condições específicas. Os tipos dessa classe são:
    \begin{itemize}
        \item 1 Grupo: Elementos pertencem a um único grupo com regras condicionais;
        \item N - Grupos: Elementos são divididos em dois ou mais grupos, frequentemente envolvendo regras de combinação e posição.
    \end{itemize}
    \item Outros: Inclui questões não contempladas nas classes anteriores, que podem combinar elementos de ordenação e agrupamento, ou que requerem cálculos matemáticos ou leitura e resolução de diagramas. Os tipos dessa classe são:
    \begin{itemize}
        \item Cálculo: Dependem exclusivamente de um cálculo envolvendo as variáveis do “Cenário”;
        \item Grupos Ordenados: Combinam as propriedades de Ordenação com as de Agrupamento;
        \item Definição: Apresentam algum conjunto de regras lógicas que devem ser seguidas ou algum conceito para encontrar a solução.
    \end{itemize}
\end{itemize}

\section{Metodologia} \label{sec:metodo}

Para assegurar que o prompt escrito fosse eficaz no auxilio da classificação das questões, os seguintes passos foram seguidos:

\subsection{Análise manual do dataset}
Inicialmente foi realizada uma revisão e análise manual das questões de dois períodos de 2003 a 2014 e 2020 a 2024, com o intuito de entender os critérios de classificação, verificar alterações drásticas na estrutura das questões entres os dois períodos e avaliar a necessidade de alguma classe ou tipo novo para a classificação.

\subsubsection{Estrutura das questões}
Durante a revisão inicial das questões foi observado que ao longo das aplicações da OBI pouco foi alterado em relação ao formato das questões, então podemos identificar uma estrutura básica:

    \begin{itemize}
        \item \textbf{Cenário:} Apresenta uma história que serve de contexto para pergunta; Contém as variáveis que serão utilizadas na pergunta (locais, eventos, objetos, etc).
        \item Existem dois tipos que devem ser levados em consideração ao escrever um prompt para classificar uma questão: Cenários Compartilhados e Cenários Únicos:
        \begin{itemize}
            \item Cenários Compartilhados: Após a descrição das regras esse cenário será utilizado por mais de uma pergunta. Em cenários compartilhados a questão sempre possuirá um título do cenário.
            \item Cenários Únicos: A regra está, completamente ou parcialmente, contida no cenário e apenas uma única pergunta utilizará esse cenário. Em cenários únicos a questão pode ou não conter um título.
        \end{itemize}
        \item \textbf{Regras:} Um conjunto de proposições que definem relações entre as variáveis (existência, posição, valor verdade).
        \begin{itemize}
            \item Nas provas mais recentes aumentou-se o uso de recursos visuais para representação de regras. Mas a utilização não está limitada as regras, podendo aparecer no cenário ou até mesmo como alternativa de resolução da questão
        \end{itemize}
        \item \textbf{Perguntas:}  Conjunto de perguntas relacionadas ao cenário e às regras:
        \begin{itemize}
            \item Em provas anteriores ao ano de 2012, as perguntas são demarcadas apenas por um número (1., 2., 3., …), já as demais são demarcadas por “Questão” seguido pelo número da pergunta, tudo em negrito.
            \item Em perguntas de cenário compartilhado, é comum perguntas que alteram regras para o escopo da pergunta.
        \end{itemize}
    \end{itemize}

\subsection{Escrita do prompt para a identificação das questões}
Uma vez definido a estrutura base de uma questão da OBI e o escopo da análise, que compreendia todas as provas do período de 2023 a 2024, escreveu-se um prompt zero-shot capaz de reconhecer as diferentes partes de uma questão e avaliar apenas a classe da questão com base nas partes reconhecidas. O prompt foi executado em um ambiente de memória temporaria, afim de não interferir com resultados posteriores. O resultado foi registrado e comparado com a análise manual.

    O prompt continha uma explicação dos itens que consistiam uma questão e uma breve descrição do eram as classes.

\subsection{Aplicação dos tipos no prompt inicial}
Após a comparação com a análise manual, o promp zero-shot foi modificado recebendo um exemplo de questão para identificação dos componentes envolvidos em uma questão e uma descrição dos tipos associadas em suas classes. Um novo ambiente de memória temporária foi utilizado e o resultado foi registrado e comparado com a análise manual e a última versão testada.

\subsection{Aplicação de exemplos de classe - tipo}
A próxima etapa foi a inserção de exemplos de questões classificadas em cada tipo no prompt. Foi realizada uma escolha cuidadosa no exemplo escolhido em cada tipo para que não acontecesse ambiguidade no entendimento das classificações. Os dados foram coletados e o resultado foi comparado com os resultados dos passos anteriores.

\subsection{Utilização do chain-of-thought prompting}
Por fim, foi escrito a versão do prompt contendo Chain-of-Thought, adicionando a linha de pensamento de classificação dos exemplos de cada tipo. Os dados foram comparados com os outros até então obtidos.

\section{Resultados}

\subsection{Desempenho dos prompts}

Nesta seção são apresentados os resultados obtidos a partir da utilização dos prompts.

\begin{figure}[ht]
\centering
\includegraphics[width=.9\textwidth]{modelosparapublicaodeartigos/Template_SBC/template-latex/chart.PNG}
\caption{Gráfico de resultado da classificação das provas de 2023 a 2024}
\label{fig:chart}
\end{figure}

    No zero-shot inicial, como o intuito era a identificação da estrutura das questões não utilizamos a classificação de tipos, portanto apenas após a segunda iteração do prompt consideramos os acertos parciais, onde o modelo classificava corretamente a classe porém errava o tipo. A ocorrência desse acerto parcial, na maioria das vezes, ocorria em questões na qual a interpretação das variáveis envolvidas podia ser aplicada em dois tipos distintos. Por exemplo, uma questão que envolvesse um grafo contendo um ciclo com regras de ordenação, poderia levar o modelo a classificar tanto como "ordenação livre" como "ordenação circular".

    Um outro detalhe a considerar-se é a presença de imagens na questão, questões que são parcialmente ou completamente dependentes de imagens são na maioria das vezes ou classificadas como "outros - definição" ou classificadas de forma errada, já que o modelo não lida tão bem com o contexto apresentado em formato de imagem.

\subsection{Avaliação das Classes e Tipos}

Sobre as questões da prova em si, foi notado um aumento no número de questões em relação as provas contempladas no livro Jogos de Lógica\cite{2}, principalmente nas fases estaduais e nacionais da olimpíada, e uma maior utilização de recursos visuais em todas as partes que compõem uma questão (contexto, regras e perguntas), apesar desses fatos as classes e tipos apresentados no livro\cite{2}, continuam sendo adequadas para classificação precisa das questões.

\section{Conclusão}\label{sec:conclu}

A realização desse projeto permitiu o desenvolvimento de um prompt que utiliza do chain-of-thougts para classificar questões da OBI, modalidade Iniciação, com base nas classes e tipos propostas no livro Jogos de Lógica\cite{2}. Além disso foi possível verificar a adequação das classes e tipos propostas.

    Como trabalhos futuros, novas melhorias e atividades podem ser realizadas, como por exemplo:

    \begin{itemize}
        \item Modificações para melhorar a precisão do prompt final;
        \item Modificações para permitir a análise de imagens de uma questão;
        \item Expandir a classificação e modificar o prompt para realizar a classificação das questões da modalidade "Programação";
        \item Aplicação da atividade em provas posteriores, com o intuito de verificar possíveis novas classes ou tipos.
    \end{itemize}

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
